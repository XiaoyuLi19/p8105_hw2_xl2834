p8105\_hw2\_xl2834
================
Xiaoyu Li
9/24/2020

``` r
library(tidyverse)
```

    ## -- Attaching packages -------------------------------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ----------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr.TrashWheel dataset.

``` r
trash_df = 
  read_xlsx(
  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
      sheet = "Mr. Trash Wheel",
      range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
mutate(
  sports_balls = round(sports_balls),
  sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data

``` r
precip_2018 = 
   read_xlsx(
     "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
     sheet = "2018 Precipitation",
     skip = 1
  ) %>%
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
   read_xlsx(
     "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
     sheet = "2017 Precipitation",
     skip = 1
  ) %>%
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Combine annual precipitation

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2017, precip_2018)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2017     1  2.34 January   
    ##  2  2017     2  1.46 February  
    ##  3  2017     3  3.57 March     
    ##  4  2017     4  3.99 April     
    ##  5  2017     5  5.64 May       
    ##  6  2017     6  1.4  June      
    ##  7  2017     7  7.09 July      
    ##  8  2017     8  4.44 August    
    ##  9  2017     9  1.95 September 
    ## 10  2017    10  0    October   
    ## # ... with 14 more rows

The dataset trash\_df contains information about Mr. Trashwheel trash
collector in Baltimore, Maryland. The dataset include variables
chip\_bags, cigarette\_butts, date, dumpster, glass\_bottles,
grocery\_bags, homes\_powered, month, plastic\_bottles, polystyrene,
sports\_balls, volume\_cubic\_yards, weight\_tons, year. There are a
total of 344 observations in the dataset. The total weight of trash
collected is 1122.45 tons. The median number of sports balls in a
dumpster in 2017 is 8.

The dataset precip\_df contains information about precipitation in
Baltimore, Maryland in 2017 and 2018. The dataset include variables
month, total, year. The total precipitation in 2018 was 70.33 inches.
There are a total of 344 observations in the dataset.

## Problem 2

``` r
subway_df = read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude,station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The dataset contains information about subway station in NYC. The
dataset include variables ada, entrance\_type, entry, line, route1,
route10, route11, route2, route3, route4, route5, route6, route7,
route8, route9, station\_latitude, station\_longitude, station\_name,
vending. I have made the variable names clearer, kept some useful
variables and converted a character variable to a logical variable. The
dimension of the dataset is `dim(subway_df)`. The data are still not
tidy, because the route information is spreading over 11 columns.

#### How many distinct stations are there?

``` r
subway_df %>% 
  distinct(station_name, line) %>% 
  nrow()
```

    ## [1] 465

There are 465 distinct stations.

#### How many stations are ADA compliant?

``` r
subway_df %>%
  distinct(station_name, line, .keep_all = TRUE) %>%
  filter(ada == TRUE) %>% 
  nrow()
```

    ## [1] 84

84 are ADA compliant.

#### What proportion of station entrances / exits without vending allow entrance?

``` r
no_vending = 
  filter(subway_df, vending == "NO")

no_vending %>% 
  filter(entry == TRUE) %>% 
  count()/count(no_vending)
```

    ##           n
    ## 1 0.3770492

Among the station entrance/exits without vending, there are 37.7% that
allow entrance.

#### Reformat the data so that route number and route name are distinct variables.

``` r
subway_df = 
  mutate(subway_df,
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
         )

subway_tidy = 
  subway_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number"
    )
```

#### How many distinct stations serve the A train?

``` r
subway_tidy %>% 
  filter(route_number == "A") %>% 
  distinct(station_name, line) %>% 
  nrow()
```

    ## [1] 60

There are 60.

#### Of the stations that serve the A train, how many are ADA compliant?

``` r
subway_tidy %>% 
  filter(route_number == "A", ada == TRUE) %>% 
  distinct(station_name, line) %>%
  nrow()
```

    ## [1] 17

There are 17.

## Problem 3

#### Step 1 Clean the data in pols-month.csv.

``` r
pols_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  pivot_longer(c(prez_gop, prez_dem),
               names_to = "president",
               values_to = "value",
               names_prefix = "prez_"
              ) %>% 
  filter(value != 0) %>% 
  select(-day, -value) %>% 
  mutate(month = as.integer(month),
         year = as.integer(year)) %>% 
  mutate(month = month.abb[month])
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

#### Step 2 Clean the data in snp.csv using a similar process.

``` r
snp_df = read_csv(
  "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  select(-day) %>% 
  relocate(year, month) %>% 
  mutate(month = as.integer(month),
         year = as.integer(year)) %>% 
  mutate(month = month.abb[month])
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

#### Step 3 Tidy the unemployment data.

``` r
unemployment_df = read_csv(
  "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percentage"
  ) %>% 
    mutate(year = as.integer(year))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

#### Join the datasets

``` r
joined_df1 = 
  left_join(pols_df, snp_df, by = c("year", "month"))

unemployment_df = 
  mutate(unemployment_df, year = as.integer(year))

result_df =
  left_join(joined_df1, unemployment_df, by = c("year", "month"))
```

The dataset pols\_df has 9 variables and 822 observations, and contains
information related to the number of national politicians who are
democratic or republican at any given time. There are variables showing
the number of governors, senators and representatives for each party,
and a variable indicating the party of the president at the given time.

The dataset snp\_df has 3 variables and 787 observations, and contains
information about Standard & Poor’s stock market index (S\&P), often
used as a representative measure of stock market as a whole.

The dataset unemployment\_df has 3 variables and 816 observations, and
shows the unemployment percentages in a given month in a year.

The result dataset has the dimension of 822, 11. It includes information
about number of governors, senators and representatives in each party,
unemployment percentages, and Standard & Poor’s stock market index in
year ranging from 1947 to 2015.
